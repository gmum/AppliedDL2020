{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Introduction_to_TensorFlow_answers.ipynb","provenance":[{"file_id":"1aeSOutaNis8Fu_5w_U0U-mxYRCcJpa7M","timestamp":1518182135874}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"qic-ui1CoF7L","colab_type":"code","colab":{}},"source":["import os\n","import sys\n","\n","import tensorflow as tf\n","import random\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from tensorflow import keras\n","from sklearn.preprocessing import OneHotEncoder\n","\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9_ImyGVxD88H","colab_type":"text"},"source":["# Some auxiliary functions"]},{"cell_type":"code","metadata":{"id":"rojHxKtSD4KX","colab_type":"code","colab":{}},"source":["def plot_learning_curves(history):\n","    pd.DataFrame(history.history).plot(figsize=(8, 5))\n","    plt.grid(True)\n","    plt.gca().set_ylim(0, 1)\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-xv7TNoX2dd9","colab_type":"text"},"source":["# Introduction to TensorFlow"]},{"cell_type":"markdown","metadata":{"id":"5-263qjD9Wdi","colab_type":"text"},"source":["TensorFlow is popular open-source deep learning library developed by Google.\n","\n","\\\\\n","\n","TensorFlow uses a dataflow graph to represent your computation in terms of the dependencies between individual operations. \n","\n","A computational graph is a series of TensorFlow operations arranged into a graph. The graph is composed of two types of objects:\n","\n","\n","*   Operations (or \"ops\"): The nodes of the graph. Operations describe calculations that consume and produce tensors.\n","*   Tensors: The edges in the graph. These represent the values that will flow through the graph.\n","\n","\\\\\n","\n","For building and training graph-constructed models, the Python program first builds a graph representing the computation, then invokes TensorFlow Session.run to send the graph for execution on the C++-based runtime. This provides:\n","\n","*    Automatic differentiation using static autodiff.\n","*    Simple deployment to a platform independent server.\n","*    Graph-based optimizations (common subexpression elimination, constant-folding, etc.).\n","*    Compilation and kernel fusion.\n","*    Automatic distribution and replication (placing nodes on the distributed system).\n","\n","\n","\\\\\n","\n","We highly recommend to read the resources from the [following link](https://www.tensorflow.org/programmers_guide/), to understand the TF architecture."]},{"cell_type":"markdown","metadata":{"id":"bisbqZ-Q3hZ7","colab_type":"text"},"source":["## Session initialization"]},{"cell_type":"markdown","metadata":{"id":"IIXcFwtD-yz4","colab_type":"text"},"source":["To evaluate tensors, instantiate a tf.Session object, informally known as a session. A session encapsulates the state of the TensorFlow runtime, and runs TensorFlow operations. If a tf.Graph is like a .py file, a tf.Session is like the python executable.\n","\n","We could define the one, global session in the following manner: *sess = tf.InteractiveSession()*.\n","\n","However the most popular method of using the session is by running:\n","\n","*with tf.Session() as sess:*"]},{"cell_type":"markdown","metadata":{"id":"I-AI50Jp32hj","colab_type":"text"},"source":["## Tensor"]},{"cell_type":"markdown","metadata":{"id":"Juuf-Ai15Utr","colab_type":"text"},"source":["TensorFlow, is a framework to define and run computations involving tensors. A tensor is a generalization of vectors and matrices to potentially higher dimensions. Internally, TensorFlow represents tensors as n-dimensional arrays of base datatypes.\n","\n","\\\\\n","\n","TensorFlow programs work by first building a graph of tf.Tensor objects, detailing how each tensor is computed based on the other available tensors and then by running parts of this graph to achieve the desired results.\n","\n","\\\\\n","\n","tf.Tensor does not exist outside the context of a single session.run call."]},{"cell_type":"markdown","metadata":{"id":"YdW3amRS-AZ_","colab_type":"text"},"source":["### Initialization"]},{"cell_type":"code","metadata":{"id":"AKUmh8bl31RU","colab_type":"code","colab":{}},"source":["node1 = tf.constant(3.0)\n","node2 = tf.constant(4, dtype=tf.int32)\n","node3 = tf.constant(0., name=\"Zero_tensor\")\n","node4 = tf.constant([1., 2., 3.])\n","node5 = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n","node6 = tf.ones([3, 3, 3])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xViut5GZ2tIq","colab_type":"code","colab":{}},"source":["print(node1)\n","print(type(node1))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9sBUaPStZSOr","colab_type":"code","colab":{}},"source":["print(node2.eval())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4fT8Mfsi2zzS","colab_type":"text"},"source":["The code given above is not working -- we should define the session before calling the eval functions to get the tensor values."]},{"cell_type":"code","metadata":{"id":"cQ1EEkjF3f4l","colab_type":"code","colab":{}},"source":["with tf.Session() as sess:\n","    print(node1)\n","    print(type(node1))\n","    print()\n","\n","    print(node2.eval())\n","    print(sess.run(node2))\n","    print()\n","\n","    print(node3.name)\n","    print()\n","\n","    print(node4.shape)\n","    print()\n","\n","    print(node5.eval())\n","    print()\n","\n","    print(node6)\n","    print(sess.run(node6))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"js8luWqG4JxY","colab_type":"text"},"source":["Now we can define the InteractiveSession"]},{"cell_type":"code","metadata":{"id":"6fy3Es2o2clg","colab_type":"code","colab":{}},"source":["sess = tf.InteractiveSession()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vnQevLMq-ClJ","colab_type":"text"},"source":["### Operations"]},{"cell_type":"code","metadata":{"id":"WkZbo8lz2dQd","colab_type":"code","colab":{}},"source":["x = tf.constant(2.)\n","y = tf.constant(3.)\n","\n","add_1 = x + y\n","add_2 = tf.add(x, y, name='our_add_node')\n","\n","print(add_1)\n","print(add_1.eval())\n","print()\n","\n","print(add_2)\n","print(add_2.eval())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L4m7teEk_58o","colab_type":"code","colab":{}},"source":["x = tf.constant(2.)\n","y = tf.constant([3., 4., 5.])\n","\n","add_3 = x + y\n","\n","print(add_3)\n","print(add_3.eval())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5TpYmOUEBBcn","colab_type":"code","colab":{}},"source":["xx = tf.random_normal(shape=(100, 10), name='xx')\n","yy = tf.random_normal(shape=(10, 2), name='yy')\n","\n","xyxy = tf.matmul(xx, yy)\n","\n","print(xyxy)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ApkVpalR6anH","colab_type":"text"},"source":["### Tensor does not exist outside the context of a single session.run call\n","\n","The result shows a different random value on each call to run, but a consistent value during a single run (out1 and out2 receive the same random input):"]},{"cell_type":"code","metadata":{"id":"scdKr0-Z6a-1","colab_type":"code","colab":{}},"source":["vec = tf.random_uniform(shape=(3,))\n","out1 = vec + 1\n","out2 = vec + 2\n","\n","print(sess.run(vec))\n","print(sess.run(vec))\n","print(sess.run((out1, out2)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"toETfx7lCgfj","colab_type":"text"},"source":["### Placeholders"]},{"cell_type":"markdown","metadata":{"id":"z6pIAIku-SEG","colab_type":"text"},"source":["A placeholder represents an entry point for us to feed actual data values\n","into tensors. It is not initialized and contains no data. A placeholder\n","generates an error if it is executed without a feed."]},{"cell_type":"markdown","metadata":{"id":"B8YIfOQriNso","colab_type":"text"},"source":["#### Placeholder for a single number"]},{"cell_type":"code","metadata":{"id":"lT_CVj_gCi8-","colab_type":"code","colab":{}},"source":["x = tf.placeholder(tf.float32, shape=[1,1])\n","y = tf.matmul(x, x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r-sP4AaACjMw","colab_type":"code","colab":{}},"source":["\"\"\" A placeholder generates an error if it is executed without a feed \"\"\"\n","print(sess.run(y))  # ERROR: will fail because x was not fed."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GYwBsVOyCjGb","colab_type":"code","colab":{}},"source":["number = [[3.]]\n","print(sess.run(y, feed_dict={x: number}))  # Will succeed."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MBlRmIFAjMRY","colab_type":"text"},"source":["#### Placeholder for a tensor with undefined length"]},{"cell_type":"code","metadata":{"id":"_AOiK4vTjRny","colab_type":"code","colab":{}},"source":["x = tf.placeholder(tf.float32, shape=[None, 5])\n","y = x * 2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZjhaSI8TjxCH","colab_type":"code","colab":{}},"source":["tensor = np.ones((1, 5))\n","print(tensor)\n","print()\n","print(sess.run(y, feed_dict={x: tensor}))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JptXq0HpkFwB","colab_type":"code","colab":{}},"source":["tensor = np.ones((10, 5))\n","print(tensor)\n","print()\n","print(sess.run(y, feed_dict={x: tensor}))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KjkiD-gbA_ti","colab_type":"text"},"source":["#### Operations on placeholders"]},{"cell_type":"code","metadata":{"id":"lWjTpu68BA1n","colab_type":"code","colab":{}},"source":["x = tf.placeholder(tf.float32, shape=[1, None])\n","y = tf.placeholder(tf.float32, shape=[1, None])\n","\n","z_1 = x + y\n","z_2 = tf.matmul(x, tf.transpose(y))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3h91PyebBAta","colab_type":"code","colab":{}},"source":["x_tensor = [[1., 2., 3.]]\n","y_tensor = [[11., 12., 13.]]\n","print(sess.run(z_1, feed_dict={x: x_tensor, y: y_tensor}))\n","print()\n","print(sess.run(z_2, feed_dict={x: x_tensor, y: y_tensor}))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5O10bIyuBKqP","colab_type":"text"},"source":["## Variable"]},{"cell_type":"markdown","metadata":{"id":"shNMrgqb-eQa","colab_type":"text"},"source":["A TensorFlow variable is the best way to represent the state manipulated\n","by your program. A tf.Variable represents a tensor whose value can be\n","changed by running ops on it.\n","Internally, a tf.Variable stores a tensor. Specific ops allow you to read and\n","modify the values of this tensor.\n","\n","\\\\\n","\n","Unlike tf.Tensor objects, a tf.Variable exists outside the context of a single session.run call.\n","\n","\\\\\n","\n","**Note:** TensorFlow 1.X relied heavily on implicitly global namespaces. When you called tf.Variable(), it would be put into the default graph, and it would remain there, even if you lost track of the Python variable pointing to it. You could then recover that tf.Variable, but only if you knew the name that it had been created with. TensorFlow 2.0 eliminates all of these mechanisms (Variables 2.0 RFC) in favor of the default mechanism: Keep track of your variables! If you lose track of a tf.Variable, it gets garbage collected."]},{"cell_type":"code","metadata":{"id":"d7Vhb-JGBPrM","colab_type":"code","colab":{}},"source":["var_1 = tf.get_variable(\"var_1\", shape=[2, 3]) # default type tf.float32, default init tf.glorot_uniform_initializer\n","var_2 = tf.get_variable(\"var_2\", shape=[5], initializer=tf.constant_initializer(1000.))\n","var_3 = tf.get_variable(\"var_3\", shape=[3, 3, 3], initializer=tf.initializers.random_normal())\n","\n","var_4 = tf.Variable(tf.constant(3., shape=[1, 2]))\n","var_5 = tf.Variable(tf.random_normal([2, 1]))\n","var_6 = tf.Variable(tf.random_uniform([1, 1]), name=\"var_6\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c1SYbbUv4TvQ","colab_type":"code","colab":{}},"source":["\"\"\" Before you can use a variable, it must be initialized!!! \"\"\"\n","print(var_1)\n","print(var_1.eval()) # ERROR: will fail because variables are not initialized!"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZA6mr_p_BPiB","colab_type":"code","colab":{}},"source":["\"\"\" Before you can use a variable, it must be initialized!!! \"\"\"\n","sess.run(tf.global_variables_initializer())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tvtfr_o53hHk","colab_type":"code","colab":{}},"source":["print(var_1)\n","print(var_1.eval())\n","print()\n","\n","print(var_2)\n","print(var_2.eval())\n","print()\n","\n","print(var_3)\n","print(sess.run(var_3))\n","print()\n","\n","print(var_4)\n","print(sess.run(var_4))\n","print()\n","\n","print(var_5)\n","print(sess.run(var_5))\n","print()\n","\n","print(var_6)\n","print(var_6.eval())\n","print()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qigzSVW-7Pqi","colab_type":"text"},"source":["### Variable exists outside the context of a single session.run call"]},{"cell_type":"code","metadata":{"id":"oYwt-lAf7QHo","colab_type":"code","colab":{}},"source":["vec = tf.get_variable(\"vec\", shape=(3,), initializer=tf.initializers.random_normal())\n","sess.run(tf.global_variables_initializer())\n","out1 = vec + 1\n","out2 = vec + 2\n","\n","print(sess.run(vec))\n","print(sess.run(vec))\n","print(sess.run((out1, out2)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HMUn9tqpCeW7","colab_type":"text"},"source":["### Variable scopes for better naming convention"]},{"cell_type":"code","metadata":{"id":"7OBWyKmpCnhR","colab_type":"code","colab":{}},"source":["with tf.variable_scope('some_scope'):\n","    var_scope = tf.get_variable(\"variable_in_scope\", shape=(2,2))\n","    \n","print(var_scope)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tlhunQfnDX5O","colab_type":"text"},"source":["With variable scopes we can reuse our variables"]},{"cell_type":"code","metadata":{"id":"Qvo7ZbEiDcFz","colab_type":"code","colab":{}},"source":["def foo():\n","    with tf.variable_scope(\"foo_non_reusing\", reuse=False):\n","        v = tf.get_variable(\"v\", [1])\n","    return v\n","\n","v1 = foo()  # Creates v.\n","v2 = foo()  # Error - we cannot reuse our variable\n","assert v1 == v2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M0nMhAYBDcg9","colab_type":"code","colab":{}},"source":["def foo():\n","    with tf.variable_scope(\"foo_reusing\", reuse=tf.AUTO_REUSE):\n","        v = tf.get_variable(\"v\", [1])\n","    return v\n","\n","v1 = foo()  # Creates v.\n","v2 = foo()  # Gets the same, existing v.\n","assert v1 == v2"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2_29uYo87Qwt","colab_type":"text"},"source":["### Computing gradients"]},{"cell_type":"code","metadata":{"id":"yS1VyVLr6FrB","colab_type":"code","colab":{}},"source":["# Reminder:\n","# var_4 = tf.Variable(tf.constant(3., shape=[1, 2]))\n","# var_5 = tf.Variable(tf.random_normal([2, 1]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bDtQynMZ_bJa","colab_type":"code","colab":{}},"source":["var_7 = tf.matmul(var_4, var_5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IS7tYaK__SBv","colab_type":"code","colab":{}},"source":["g = tf.gradients(var_7, [var_4, var_5])\n","print(g)\n","print(g[0].eval())\n","print(g[1].eval())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V_eatiVgCRCX","colab_type":"code","colab":{}},"source":["x_1 = tf.constant(2., shape=[2,1])\n","x_2 = tf.constant(3., shape=[1,2])\n","y = tf.matmul(x_1, x_2)\n","\n","g = tf.gradients(y, [x_1, x_2])\n","print(g)\n","print(g[0].eval())\n","print(g[1].eval())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6m-uRp4ABGsR","colab_type":"text"},"source":["## Optimizers"]},{"cell_type":"markdown","metadata":{"id":"Yf7rqwFFhv5-","colab_type":"text"},"source":["In TensorFlow one can use fast, efficient gradient optimizers to minimize the given function. \\\\\n","In the following example we will show how to use optimizers in TF, by minimizing x^2 function, with using of the Gradient Decent Optimizer. "]},{"cell_type":"markdown","metadata":{"id":"NiEPD-owirIv","colab_type":"text"},"source":["#### Defining the starting point x and the function y = x^2\n","\n","Notice, that the starting point should be initialized as a variable, not a tensor, as the optimizer have to change its value, by repeatedly subtracting the gradient of function in order to minimize y value."]},{"cell_type":"code","metadata":{"id":"FkIlIp87BQlg","colab_type":"code","colab":{}},"source":["x = tf.get_variable(\"opt_x\", dtype=tf.float32, initializer=tf.constant_initializer(1000.), shape=[1, 1])\n","y = tf.pow(x, [2.])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xsRMKuqHjvvb","colab_type":"text"},"source":["#### Defining the Gradient Descent Optimizer"]},{"cell_type":"code","metadata":{"id":"xdGNRmjMBQdg","colab_type":"code","colab":{}},"source":["train_step = tf.train.GradientDescentOptimizer(0.1).minimize(y)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MrgPHWVDkH9u","colab_type":"text"},"source":["#### Iterate to minimize function"]},{"cell_type":"code","metadata":{"id":"cg639E8fB-8Y","colab_type":"code","colab":{}},"source":["with tf.Session() as sess:\n","    sess.run(tf.global_variables_initializer())\n","    print(\"x = \", x.eval())\n","    print(\"y = \", y.eval())\n","    for i in range(200):\n","        train_step.run()\n","        if i % 10 == 0:\n","            print(x.eval())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5l6ZkbE8BzLH","colab_type":"code","colab":{}},"source":["\"\"\" Optimizer needs variables that can be mutated in order to minimize a function! \"\"\"\n","x = tf.constant(1000.)\n","y = tf.pow(x, [2.])\n","\n","train_step = tf.train.GradientDescentOptimizer(0.1).minimize(y) # ERROR: there are no gradients provided for any variable!"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6ai5sMikTUjE","colab_type":"text"},"source":["Now we can close our session"]},{"cell_type":"code","metadata":{"id":"gdoiEeXXB1bQ","colab_type":"code","colab":{}},"source":["sess.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tSw74e7NTVjQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-5eoWqEvCexW","colab_type":"text"},"source":["# Image classification with tf and tf.keras"]},{"cell_type":"markdown","metadata":{"id":"AZP5aPmgmUMY","colab_type":"text"},"source":["In the following section we will use tf and tf.keras library to create FNNs that classifies the fashion MNIST dataset.\n","\n","Some parts of this code comes from the [tf 2.0 tutorial](https://github.com/ageron/tf2_course) by Aurélien Geron."]},{"cell_type":"markdown","metadata":{"id":"xdPjGgPlCmuy","colab_type":"text"},"source":["\n","## Load the Fashion MNIST dataset\n"]},{"cell_type":"code","metadata":{"id":"4pjAjNbUbWfF","colab_type":"code","colab":{}},"source":["fashion_mnist = keras.datasets.fashion_mnist\n","\n","(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n","\n","print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"baySnikQCpbw","colab_type":"code","colab":{}},"source":["X_train = X_train.reshape((X_train.shape[0], -1))\n","X_test = X_test.reshape((X_test.shape[0], -1))\n","\n","print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PlAHdbA6HTZc","colab_type":"code","colab":{}},"source":["X_train = X_train / 255\n","X_test = X_test / 255"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Sy-QRnVCpek","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gT8ynDUsC2Mx","colab_type":"text"},"source":["## Build a classification neural network with Keras sequential model"]},{"cell_type":"markdown","metadata":{"id":"f6GTCRPjnQMg","colab_type":"text"},"source":["Build a Sequential model ([keras.models.Sequential](https://https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential)), with the following layers:\n","\n","1.   Dense layer ([keras.layers.Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)) with 300 neurons (aka units), and the \"relu\" activation function. Since it is the first layer in your model, you should specify the input_shape argument, leaving out the batch size: [784].\n","2.   Another Dense layer with 100 neurons, also with the \"relu\" activation function.\n","3.  A final Dense layer with 10 neurons (one per class), and with the \"softmax\" activation function to ensure that the sum of all the estimated class probabilities for each image is equal to 1.\n","\n","\n","You can do it by calling the Sequential without any argument, then and add layers to it by calling its add() method or by passing a list containing the 3 layers to the constructor of the Sequential model."]},{"cell_type":"code","metadata":{"id":"F7bzUQDtCpjN","colab_type":"code","colab":{}},"source":["model = keras.models.Sequential([\n","    keras.layers.Dense(300, activation=\"relu\", input_shape=[784]),\n","    keras.layers.Dense(100, activation=\"relu\"),\n","    keras.layers.Dense(10, activation=\"softmax\")\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oLcSV2PaozLP","colab_type":"text"},"source":["Call the model's **summary()** method and examine the output."]},{"cell_type":"code","metadata":{"id":"rR6cVOsqCpl6","colab_type":"code","colab":{}},"source":["model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rEML4OHso_UH","colab_type":"text"},"source":["After a model is created, you must call its **compile()** method to specify the loss function and the optimizer to use.\n","\n","In this case, you want to use:\n","\n","*   the **sparse_categorical_crossentropy** loss -- cross-entropy loss but for labels that are not one-hot encoded, but that are integers with the class number\n","*   the **sgd** optimizer -- stochastic gradient descent. \n","*   you can optionally specify a list of additional metrics that should be measured during training. In this case you should specify **metrics=[\"\"accuracy\"]**. \n","\n","Note: you can find more loss functions in [keras.losses](https://www.tensorflow.org/api_docs/python/tf/keras/losses), more metrics in [keras.metrics](https://www.tensorflow.org/api_docs/python/tf/keras/metrics) and more optimizers in [keras.optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers).\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"Ax-1aixsCpog","colab_type":"code","colab":{}},"source":["model.compile(loss=\"sparse_categorical_crossentropy\",\n","              optimizer=\"adam\", metrics=[\"accuracy\"])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AqAiV3VgqdUL","colab_type":"text"},"source":["Now your model is ready to be trained. Call its **fit()** method, passing it the input features (X_train) and the target classes (y_train). Set epochs=10 (or else it will just run for a single epoch). \n","\n","You can also (optionally) pass the validation data by setting validation_data=(X_valid, y_valid). If you do, Keras will compute the loss and the additional metrics (the accuracy in this case) on the validation set at the end of each epoch. \n","\n","If the performance on the training set is much better than on the validation set, your model is probably overfitting the training set (or there is a bug, such as a mismatch between the training set and the validation set). \n","\n","**Note**: the fit() method will return a History object containing training stats. Make sure to preserve it (history = model.fit(...))."]},{"cell_type":"code","metadata":{"id":"1ZWa36BFEfTI","colab_type":"code","colab":{}},"source":["history = model.fit(X_train, y_train, epochs=10,\n","                    validation_data=(X_test, y_test))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jbFlrbjUqzQg","colab_type":"text"},"source":["Plot the learning curves for our model"]},{"cell_type":"code","metadata":{"id":"pz7MCtyWCpuO","colab_type":"code","colab":{}},"source":["plot_learning_curves(history)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qGyeADe-q7-H","colab_type":"text"},"source":["Call the model's **evaluate()** method, passing it the test set (X_test and y_test). This will compute the loss (cross-entropy) on the test set, as well as all the additional metrics (in this case, the accuracy)."]},{"cell_type":"code","metadata":{"id":"XOPldrw5Cpw9","colab_type":"code","colab":{}},"source":["test_loss, test_acc = model.evaluate(X_test, y_test)\n","test_loss, test_acc"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U-Lc6lZZrH5A","colab_type":"text"},"source":["You can also estimate the probability of each class for each instance for a given dataset, by calling the model's **predict()** method."]},{"cell_type":"code","metadata":{"id":"1b8_TobhQWPG","colab_type":"code","colab":{}},"source":["model.predict(X_test[0:10])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CaJyRGaAJQ2e","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4OSwGHyhKX7e","colab_type":"text"},"source":["## Build a classification neural network with Keras functional API"]},{"cell_type":"markdown","metadata":{"id":"yPGCcwberr2C","colab_type":"text"},"source":["The tf.keras.Sequential model is a simple stack of layers that cannot represent arbitrary models. Use the Keras functional API to build complex model topologies such as:\n","\n","*    Multi-input models,\n","*    Multi-output models,\n","*    Models with shared layers (the same layer called several times),\n","*    Models with non-sequential data flows (e.g. residual connections).\n","\n","Building a model with the functional API works like this:\n","\n","1.    A layer instance is callable and returns a tensor.\n","2.    Input tensors and output tensors are used to define a tf.keras.Model instance.\n","3.    This model is trained just like the Sequential model.\n","\n","In the following subsection we will train the fashion-MNIST classifier using the functional API."]},{"cell_type":"code","metadata":{"id":"8E-3kq9Gs-l3","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y2GfJjMTs7I0","colab_type":"text"},"source":["Define the following layers of your new model:\n","\n","1.   [keras.layers.Input](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Input) layer to represent the inputs. Don't forget to specify the input shape.\n","2.   Dense layer ([keras.layers.Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)) with 300 neurons (aka units), and the \"relu\" activation function. Since you already specified the input layer of the network, you no longer need to specify the input_shape argument.\n","3.   Another Dense layer with 100 neurons, also with the \"relu\" activation function.\n","4.  A final Dense layer with 10 neurons (one per class), and with the \"softmax\" activation function to ensure that the sum of all the estimated class probabilities for each image is equal to 1."]},{"cell_type":"code","metadata":{"id":"CzYvFgZHJQ9C","colab_type":"code","colab":{}},"source":["input_layer = keras.layers.Input(shape=X_train.shape[1:])\n","hidden1 = keras.layers.Dense(300, activation=\"relu\")(input_layer)\n","hidden2 = keras.layers.Dense(100, activation=\"relu\")(hidden1)\n","output_layer = keras.layers.Dense(10, activation=\"softmax\")(hidden2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jJtXape0t4Od","colab_type":"text"},"source":["Now create a [keras.models.Model](https://www.tensorflow.org/api_docs/python/tf/keras/models/Model) and specify its inputs and outputs (e.g., **inputs=[input]**)."]},{"cell_type":"code","metadata":{"id":"UJz9MqDvJRLF","colab_type":"code","colab":{}},"source":["model = keras.models.Model(inputs=[input_layer], outputs=[output_layer])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8uVDygBjuD4V","colab_type":"text"},"source":["In functional API you use your this model just like a Sequential model: you need to compile it, display its summary, train it, evaluate it and use it to make predictions."]},{"cell_type":"code","metadata":{"id":"vlzprnb0JRPc","colab_type":"code","colab":{}},"source":["model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LlWQwCPZQQ15","colab_type":"code","colab":{}},"source":["model.compile(loss=\"sparse_categorical_crossentropy\",\n","              optimizer=\"adam\", metrics=[\"accuracy\"])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8K-hlUQcqOc3","colab_type":"code","colab":{}},"source":["tensorboard_cbk = keras.callbacks.TensorBoard(log_dir='/full_path_to_your_logs')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Kif0Jr5JRNq","colab_type":"code","colab":{}},"source":["model.fit(X_train, y_train, epochs=10, batch_size=32,\n","          validation_data=(X_test, y_test))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Ntg4ttjJQ7d","colab_type":"code","colab":{}},"source":["test_loss, test_acc = model.evaluate(X_test, y_test)\n","test_loss, test_acc"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xkY-R-yrJQ5e","colab_type":"code","colab":{}},"source":["model.predict(X_test[0:10])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yRC6_Qq-JQ04","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XHNdaFdsQdA-","colab_type":"text"},"source":["## Build a classification neural network with TensorFlow"]},{"cell_type":"markdown","metadata":{"id":"6ZKpI8p-uwxV","colab_type":"text"},"source":["You can also use lower level APIs to create your model. \n","\n","In the following subsection we will build the model, using classic tf model creation pipeline."]},{"cell_type":"markdown","metadata":{"id":"NYaBmBryvpjb","colab_type":"text"},"source":["### Create one-hot-encoding of train and test labels"]},{"cell_type":"code","metadata":{"id":"5PFnjwdHRYbo","colab_type":"code","colab":{}},"source":["enc = OneHotEncoder(sparse=False, categories='auto')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PaKMxybERYhX","colab_type":"code","colab":{}},"source":["y_train = enc.fit_transform(y_train.reshape(-1, 1))\n","y_test = enc.transform(y_test.reshape(-1, 1))\n","\n","print(y_train.shape, y_test.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wWcR2WjFvwra","colab_type":"text"},"source":["### Define model"]},{"cell_type":"markdown","metadata":{"id":"JBrhqf0Yv9UN","colab_type":"text"},"source":["**Create placeholders for training data.**\n","\n","Remember about a propper shape of training images (in mnist.train.images every digit is a 784D vector) and labels (In training dataset labels are in one-hot-encoding form)."]},{"cell_type":"code","metadata":{"id":"lz2fK92sJQy2","colab_type":"code","colab":{}},"source":["x_placeholder = tf.placeholder(tf.float32, [None, 784])\n","y_placeholder = tf.placeholder(tf.float32, [None, 10])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AmxRNNhtwCH9","colab_type":"text"},"source":["**Define layers of your new model**\n","\n","In lower lvl APIs you can still use the tf.keras layers. Please define the following layers of your network:\n","\n","1.    Dense layer (keras.layers.Dense) with 300 neurons, and the \"relu\" activation function. You don't need to specify the input_shape argument nor define the keras input layer of the network, as you will pass the input data into placeholders that you have already defined.\n","2.    Another Dense layer with 100 neurons, also with the \"relu\" activation function.\n","3.    A final Dense layer with 10 neurons (one per class), **without any activation function** -- returning the logits (not softmax), together with the specified loss function ensures the numerical stability.\n","\n"]},{"cell_type":"code","metadata":{"id":"hueJWwsDRYUs","colab_type":"code","colab":{}},"source":["hidden1 = keras.layers.Dense(300, activation=\"relu\")(x_placeholder)\n","hidden2 = keras.layers.Dense(100, activation=\"relu\")(hidden1)\n","logits = keras.layers.Dense(10, activation=None)(hidden2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8XTVbIAUJQvt","colab_type":"code","colab":{}},"source":["print(x_placeholder)\n","print(y_placeholder)\n","print()\n","print(hidden1)\n","print(hidden2)\n","print(logits)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LXWRFXNPwIZs","colab_type":"text"},"source":["**Define the loss function**\n","\n","This is the place to define the loss function for our model. Cross-entropy is the classical approach to use in the multi-label classification task.  However for numerical stability we didn't use the softmax activation function (so as we are taking the log of softmax -- logits), in this case, you could use the [tf.nn.softmax_cross_entropy_with_logits_v2](https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits_v2) loss function."]},{"cell_type":"code","metadata":{"id":"--fLUl2uTZ9D","colab_type":"code","colab":{}},"source":["cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_placeholder, logits=logits)\n","# cross_entropy = tf.losses.softmax_cross_entropy(onehot_labels=y_placeholder, logits=logits)\n","cross_entropy = tf.reduce_mean(cross_entropy)\n","print(cross_entropy)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GN5zD_7hxIJL","colab_type":"text"},"source":["**Define the optimizer**\n","\n","Use the [SGD optimizer](https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer) and set it to minimize the loss function."]},{"cell_type":"code","metadata":{"id":"Dfz2HjkITatx","colab_type":"code","colab":{}},"source":["opt = tf.train.GradientDescentOptimizer(0.1)\n","train_step = opt.minimize(cross_entropy)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zQWHC4aczRPW","colab_type":"text"},"source":["** Check whether softmax classifier returns correct predictions and calculate the accuracy**"]},{"cell_type":"code","metadata":{"id":"OjAbfzdUTa0W","colab_type":"code","colab":{}},"source":["\"\"\" Create a vector that tells us, whether the predictions from our net - logits\n","    are equal to the correct digit labels - y_placeholder. \"\"\"\n","correct_prediction = tf.equal(tf.argmax(y_placeholder, 1), tf.argmax(logits, 1))\n","correct_prediction = tf.cast(correct_prediction, tf.float32)\n","\n","\"\"\" Calculate the accurracy of correct predictions \"\"\"\n","accuracy = tf.reduce_mean(correct_prediction)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d9s4W8Gmyr33","colab_type":"text"},"source":["**Train the model**\n","\n","Please notice, that before training the model, you should define the tf.Session and initialize all variables.\n","\n","**Note**: after session ends, weights of the trained model are lost!"]},{"cell_type":"code","metadata":{"id":"6ATkyiFGgFxe","colab_type":"code","colab":{}},"source":["epoch_num = 10\n","batch_size = 32\n","set_size = X_train.shape[0]\n","\n","with tf.Session() as sess:\n","    sess.run(tf.global_variables_initializer())\n","    \n","    for epoch in range(epoch_num):\n","        perm = np.random.permutation(set_size)\n","        X_train = X_train[perm, :]\n","        y_train = y_train[perm, :]\n","\n","        for i in range(0, set_size, batch_size):\n","            step_size = min(batch_size, set_size - i)\n","\n","            if step_size > 1:\n","                y_batch = y_train[i:(i + step_size), :]\n","                x_batch = X_train[i:(i + step_size), :]\n","                train_step.run(feed_dict={\n","                                x_placeholder: x_batch, y_placeholder: y_batch})\n","                \n","        validation_accuracy = accuracy.eval(feed_dict={\n","                                  x_placeholder: X_test, y_placeholder: y_test})\n","        print('step: {}, validation accuracy: {}'.format(epoch, validation_accuracy))\n","\n","\n","    # Print the test set accuracy\n","    print('test accuracy: {}'.format(accuracy.eval(feed_dict={\n","                           x_placeholder: X_test, y_placeholder: y_test})))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VEN95r0UzHgu","colab_type":"code","colab":{}},"source":["with tf.Session() as sess:\n","    sess.run(tf.global_variables_initializer())\n","    \n","    # Print the test set accuracy\n","    print('test accuracy: {}'.format(accuracy.eval(feed_dict={\n","                           x_placeholder: X_test, y_placeholder: y_test})))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Y9JW2ktgF1O","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DypFE84sEXPh","colab_type":"text"},"source":["## You could also specify your own custom tf.keras layers\n","\n","You could create a custom layer by subclassing tf.keras.layers.Layer and implementing the following methods:\n","\n","*    build: Create the weights of the layer. Add weights with the add_weight method.\n","*    call: Define the forward pass.\n","*    compute_output_shape: Specify how to compute the output shape of the layer given the input shape.\n","*    Optionally, a layer can be serialized by implementing the get_config method and the from_config class method.\n","\n","\n","\\\\\n","\n","Now let's create a custom layer with its own weights. Use the following template to create a MyDense layer that computes $\\phi(\\mathbf{X} \\mathbf{W}) + \\mathbf{b}$, where $\\phi$ is the (optional) activation function, $\\mathbf{X}$ is the input data, $\\mathbf{W}$ represents the kernel (i.e., connection weights), and $\\mathbf{b}$ represents the biases, then train and evaluate a model using this instead of a regular Dense layer."]},{"cell_type":"code","metadata":{"id":"vktIAJVVgFuW","colab_type":"code","colab":{}},"source":["class MyDense(keras.layers.Layer):\n","    def __init__(self, units, activation=None, **kwargs):\n","        self.units = units\n","        self.activation = keras.layers.Activation(activation)\n","        super(MyDense, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        shape = tf.TensorShape((input_shape[1], self.units))\n","        self.kernel = self.add_weight(name='kernel', \n","                                      shape=shape,\n","                                      initializer='uniform',\n","                                      trainable=True)\n","        self.biases = self.add_weight(name='bias', \n","                                      shape=(self.units,),\n","                                      initializer='zeros',\n","                                      trainable=True)\n","        super(MyDense, self).build(input_shape)\n","\n","    def call(self, X):\n","        return self.activation(tf.matmul(X, self.kernel) + self.biases)    \n","    \n","    def compute_output_shape(self, input_shape):\n","        shape = tf.TensorShape(input_shape).as_list()\n","        shape[-1] = self.units\n","        return tf.TensorShape(shape)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W5R0D5bwGbS3","colab_type":"text"},"source":["**Now please use the code you have writen earlier to train the model with your custom layer instead od keras.layers.Dense**\n","\n","You could use keras Sequence API, keras functional API or TensorFlow API"]},{"cell_type":"code","metadata":{"id":"jtELBjofTayO","colab_type":"code","colab":{}},"source":["model = keras.models.Sequential([\n","    MyDense(300, activation=\"relu\", input_shape=X_train.shape[1:]),\n","    MyDense(100, activation=\"relu\", input_shape=X_train.shape[1:]),\n","    MyDense(10, activation=\"softmax\")\n","])\n","\n","model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\")\n","model.fit(X_train, y_train, epochs=10,\n","          validation_data=(X_test, y_test))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zEakcOZTGu1N","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZAo1AYFOCjkH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}